{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "Here we prepare data as 1 min level kline for BTC from 2019.1.1 to 2020.5.2 in bitfinex exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install -e .. -U\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TZ = 'Asia/Shanghai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/data'\n",
    "data_platform_list = ['BITFINEX']\n",
    "data_symbol_list = ['BTC']\n",
    "\n",
    "data_df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for platform in data_platform_list:\n",
    "    for symbol in data_symbol_list:\n",
    "        pkl_file_path = data_path+'/'+symbol+'_USD_'+platform+'_latest.pkl'\n",
    "        pandas_df = pd.read_pickle(pkl_file_path)\n",
    "        #data_df_list.append(pkl_file.add_prefix(platform+'_'+symbol+':'))\n",
    "        data_df_list.append(pandas_df)\n",
    "data = pd.concat(data_df_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enginnering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tactical indicators etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['timestamp'] = data.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 16:00:00+08:00</th>\n",
       "      <td>3850.000000</td>\n",
       "      <td>3850.000000</td>\n",
       "      <td>3849.600000</td>\n",
       "      <td>3849.600000</td>\n",
       "      <td>0.443293</td>\n",
       "      <td>2019-01-01 16:00:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 16:01:00+08:00</th>\n",
       "      <td>3849.500000</td>\n",
       "      <td>3853.000000</td>\n",
       "      <td>3849.400000</td>\n",
       "      <td>3853.000000</td>\n",
       "      <td>9.085920</td>\n",
       "      <td>2019-01-01 16:01:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 16:02:00+08:00</th>\n",
       "      <td>3853.000000</td>\n",
       "      <td>3857.000000</td>\n",
       "      <td>3852.960000</td>\n",
       "      <td>3853.200000</td>\n",
       "      <td>8.213360</td>\n",
       "      <td>2019-01-01 16:02:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 16:03:00+08:00</th>\n",
       "      <td>3853.000000</td>\n",
       "      <td>3853.100000</td>\n",
       "      <td>3851.200000</td>\n",
       "      <td>3852.200000</td>\n",
       "      <td>6.385190</td>\n",
       "      <td>2019-01-01 16:03:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 16:04:00+08:00</th>\n",
       "      <td>3852.200000</td>\n",
       "      <td>3852.300000</td>\n",
       "      <td>3852.200000</td>\n",
       "      <td>3852.300000</td>\n",
       "      <td>0.504622</td>\n",
       "      <td>2019-01-01 16:04:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-07 15:55:00+08:00</th>\n",
       "      <td>15428.349581</td>\n",
       "      <td>15437.000000</td>\n",
       "      <td>15428.000000</td>\n",
       "      <td>15436.374894</td>\n",
       "      <td>1.040375</td>\n",
       "      <td>2020-11-07 15:55:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-07 15:56:00+08:00</th>\n",
       "      <td>15434.000000</td>\n",
       "      <td>15447.000000</td>\n",
       "      <td>15434.000000</td>\n",
       "      <td>15443.000000</td>\n",
       "      <td>5.073000</td>\n",
       "      <td>2020-11-07 15:56:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-07 15:57:00+08:00</th>\n",
       "      <td>15441.000000</td>\n",
       "      <td>15446.000000</td>\n",
       "      <td>15441.000000</td>\n",
       "      <td>15446.000000</td>\n",
       "      <td>1.608000</td>\n",
       "      <td>2020-11-07 15:57:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-07 15:58:00+08:00</th>\n",
       "      <td>15443.786243</td>\n",
       "      <td>15443.786243</td>\n",
       "      <td>15430.460723</td>\n",
       "      <td>15430.460723</td>\n",
       "      <td>0.692501</td>\n",
       "      <td>2020-11-07 15:58:00+08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-07 15:59:00+08:00</th>\n",
       "      <td>15433.000000</td>\n",
       "      <td>15440.000000</td>\n",
       "      <td>15427.000000</td>\n",
       "      <td>15431.000000</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>2020-11-07 15:59:00+08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>945426 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   open          high           low  \\\n",
       "2019-01-01 16:00:00+08:00   3850.000000   3850.000000   3849.600000   \n",
       "2019-01-01 16:01:00+08:00   3849.500000   3853.000000   3849.400000   \n",
       "2019-01-01 16:02:00+08:00   3853.000000   3857.000000   3852.960000   \n",
       "2019-01-01 16:03:00+08:00   3853.000000   3853.100000   3851.200000   \n",
       "2019-01-01 16:04:00+08:00   3852.200000   3852.300000   3852.200000   \n",
       "...                                 ...           ...           ...   \n",
       "2020-11-07 15:55:00+08:00  15428.349581  15437.000000  15428.000000   \n",
       "2020-11-07 15:56:00+08:00  15434.000000  15447.000000  15434.000000   \n",
       "2020-11-07 15:57:00+08:00  15441.000000  15446.000000  15441.000000   \n",
       "2020-11-07 15:58:00+08:00  15443.786243  15443.786243  15430.460723   \n",
       "2020-11-07 15:59:00+08:00  15433.000000  15440.000000  15427.000000   \n",
       "\n",
       "                                  close    volume                 timestamp  \n",
       "2019-01-01 16:00:00+08:00   3849.600000  0.443293 2019-01-01 16:00:00+08:00  \n",
       "2019-01-01 16:01:00+08:00   3853.000000  9.085920 2019-01-01 16:01:00+08:00  \n",
       "2019-01-01 16:02:00+08:00   3853.200000  8.213360 2019-01-01 16:02:00+08:00  \n",
       "2019-01-01 16:03:00+08:00   3852.200000  6.385190 2019-01-01 16:03:00+08:00  \n",
       "2019-01-01 16:04:00+08:00   3852.300000  0.504622 2019-01-01 16:04:00+08:00  \n",
       "...                                 ...       ...                       ...  \n",
       "2020-11-07 15:55:00+08:00  15436.374894  1.040375 2020-11-07 15:55:00+08:00  \n",
       "2020-11-07 15:56:00+08:00  15443.000000  5.073000 2020-11-07 15:56:00+08:00  \n",
       "2020-11-07 15:57:00+08:00  15446.000000  1.608000 2020-11-07 15:57:00+08:00  \n",
       "2020-11-07 15:58:00+08:00  15430.460723  0.692501 2020-11-07 15:58:00+08:00  \n",
       "2020-11-07 15:59:00+08:00  15431.000000  0.066774 2020-11-07 15:59:00+08:00  \n",
       "\n",
       "[945426 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "import talib\n",
    "\n",
    "# Moving averages\n",
    "data['ma5m'] = talib.MA(data['close'], timeperiod = 5) / data['close'] \n",
    "data['ma10m'] = talib.MA(data['close'], timeperiod = 10) / data['close'] \n",
    "data['ma1h'] = talib.MA(data['close'], timeperiod = 60) / data['close'] \n",
    "data['ma4h'] = talib.MA(data['close'], timeperiod = 240) / data['close'] \n",
    "data['ma12h'] = talib.MA(data['close'], timeperiod = 720) / data['close'] \n",
    "data['ma1d'] = talib.MA(data['close'], timeperiod = 1440) / data['close']\n",
    "data['ma5d'] = talib.MA(data['close'], timeperiod = 7200) / data['close'] \n",
    "data['ma10d'] = talib.MA(data['close'], timeperiod = 14400) / data['close'] \n",
    "data['ma30d'] = talib.MA(data['close'], timeperiod = 43200) / data['close'] \n",
    "\n",
    "\n",
    "# Standard deviation\n",
    "data['std5m'] = talib.STDDEV(data['close'], timeperiod=5)/ data['close'] \n",
    "data['std10m'] = talib.STDDEV(data['close'], timeperiod = 10) / data['close'] \n",
    "data['std1h'] = talib.STDDEV(data['close'], timeperiod = 60) / data['close'] \n",
    "data['std4h'] = talib.STDDEV(data['close'], timeperiod = 240) / data['close'] \n",
    "data['std12h'] = talib.STDDEV(data['close'], timeperiod = 720) / data['close'] \n",
    "data['std1d'] = talib.STDDEV(data['close'], timeperiod = 1440) / data['close']\n",
    "data['std5d'] = talib.STDDEV(data['close'], timeperiod = 7200) / data['close'] \n",
    "data['std10d'] = talib.STDDEV(data['close'], timeperiod = 14400) / data['close'] \n",
    "data['std30d'] = talib.STDDEV(data['close'], timeperiod = 43200) / data['close'] \n",
    "\n",
    "# Closeness to hundred / thousand\n",
    "data['dis100'] = (data['close'] % 100) / 100 \n",
    "data['dis1000'] = (data['close'] % 1000) / 1000 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['up_5%_in_1d_label'] = data['close'] > data['close'].shift(-1440) * 1.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Strategy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Strategy Example\n",
    "\n",
    "refernces: https://towardsdatascience.com/model-design-and-selection-with-scikit-learn-18a29041d02a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_time = pd.Timestamp('2019-01-01', tz=TZ)\n",
    "train_end_time = pd.Timestamp('2019-12-31', tz=TZ)\n",
    "val_start_time = pd.Timestamp('2020-01-01', tz=TZ)\n",
    "val_end_time = pd.Timestamp('2020-06-01', tz=TZ)\n",
    "test_start_time = pd.Timestamp('2020-06-01', tz=TZ)\n",
    "test_end_time = pd.Timestamp('2020-11-01', tz=TZ)\n",
    "\n",
    "train_data = data.loc[train_start_time:train_end_time]\n",
    "val_data = data.loc[train_start_time:train_end_time]\n",
    "test_data = data.loc[test_start_time:test_end_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = ['ma5m','ma10m','ma1h','ma4h','ma12h','ma1d','ma5d','ma10d','ma30d', \\\n",
    "               'std5m','std10m','std1h','std4h','std12h','std1d','std5d','std10d','std30d',\\\n",
    "               'dis100', 'dis1000']\n",
    "label = ['up_5%_in_1d_label']\n",
    "\n",
    "X_train = train_data[feature_set]\n",
    "y_train = train_data[label]\n",
    "X_val = train_data[feature_set]\n",
    "y_val = train_data[label]\n",
    "X_test = test_data[feature_set]\n",
    "y_test = test_data[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "up_5%_in_1d_label    0.062166\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum() / y_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model and hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading, visualizing, and preprocessing data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Sample Reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_reweight import SampleReweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMITED_SAMPLE = True\n",
    "EXAMPLES = 40000 if LIMITED_SAMPLE else X_train.shape[0]\n",
    "\n",
    "# number of submodels\n",
    "K = 10\n",
    "\n",
    "# initialize sample weights and parameters\n",
    "w = np.ones(X_train.shape[0])[:EXAMPLES]\n",
    "\n",
    "ALPHA_1 = 1\n",
    "ALPHA_2 = 1\n",
    "NUM_BINS = 10\n",
    "GAMMA = 0.9\n",
    "\n",
    "# initialize sample reweighting\n",
    "SR = SampleReweight(X_train[:EXAMPLES], y_train[:EXAMPLES].to_numpy(dtype=int), a1=ALPHA_1, a2=ALPHA_2, b=NUM_BINS, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clfs = [GradientBoostingClassifier(random_state=0) for i in range(K)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Sub-model Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]C:\\Users\\Yuan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5627]\n",
      " [0.5669]\n",
      " [0.567 ]\n",
      " ...\n",
      " [0.048 ]\n",
      " [0.046 ]\n",
      " [0.0354]]\n",
      "[[0.5627]\n",
      " [0.5669]\n",
      " [0.567 ]\n",
      " ...\n",
      " [0.048 ]\n",
      " [0.046 ]\n",
      " [0.0354]]\n",
      "[[1.000e-04]\n",
      " [6.664e-01]\n",
      " [6.665e-01]\n",
      " ...\n",
      " [3.337e-01]\n",
      " [3.330e-01]\n",
      " [1.000e+00]]\n",
      "(10000,)\n",
      "(10000,)\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuan\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Yuan\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                          | 1/10 [00:04<00:42,  4.67s/it]C:\\Users\\Yuan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 10. 10. ... 10. 10. 10.]\n",
      "[[0.5627]\n",
      " [0.5669]\n",
      " [0.567 ]\n",
      " ...\n",
      " [0.048 ]\n",
      " [0.046 ]\n",
      " [0.0354]]\n",
      "[[0.5627 0.5627]\n",
      " [0.5669 0.5669]\n",
      " [0.567  0.567 ]\n",
      " ...\n",
      " [0.048  0.048 ]\n",
      " [0.046  0.046 ]\n",
      " [0.0354 0.0354]]\n",
      "[[1.000e-04]\n",
      " [6.664e-01]\n",
      " [6.665e-01]\n",
      " ...\n",
      " [3.337e-01]\n",
      " [3.330e-01]\n",
      " [1.000e+00]]\n",
      "(10000,)\n",
      "(10000,)\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuan\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Yuan\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                  | 2/10 [00:09<00:37,  4.66s/it]C:\\Users\\Yuan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 10. 10. ... 10. 10. 10.]\n",
      "[[0.5627]\n",
      " [0.5669]\n",
      " [0.567 ]\n",
      " ...\n",
      " [0.048 ]\n",
      " [0.046 ]\n",
      " [0.0354]]\n",
      "[[0.5627 0.5627 0.5627]\n",
      " [0.5669 0.5669 0.5669]\n",
      " [0.567  0.567  0.567 ]\n",
      " ...\n",
      " [0.048  0.048  0.048 ]\n",
      " [0.046  0.046  0.046 ]\n",
      " [0.0354 0.0354 0.0354]]\n",
      "[[1.000e-04]\n",
      " [6.664e-01]\n",
      " [6.665e-01]\n",
      " ...\n",
      " [3.337e-01]\n",
      " [3.330e-01]\n",
      " [1.000e+00]]\n",
      "(10000,)\n",
      "(10000,)\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[10. 10. 10. ... 10. 10. 10.]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yuan\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3334: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Yuan\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                          | 3/10 [00:13<00:32,  4.64s/it]C:\\Users\\Yuan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                          | 3/10 [00:17<00:41,  5.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-69ce2d1a59b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mEXAMPLES\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mEXAMPLES\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreweight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    499\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    556\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m                 random_state, X_idx_sorted, X_csc, X_csr)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    212\u001b[0m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \"\"\"\n\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tqdm import tqdm\n",
    "    submodels = tqdm(clfs)\n",
    "except ImportError:\n",
    "    submodels = clfs\n",
    "    \n",
    "for model in submodels:\n",
    "    model.fit(X_train[:EXAMPLES], y_train[:EXAMPLES], sample_weight=w)\n",
    "    w = SR.reweight(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = np.mean(np.assarray([clf.decision_function(X_test) for clf in clfs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(labels, scores):\n",
    "    lw = 2\n",
    "    fpr, tpr, _ = roc_curve(labels, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='(AUC = %0.3f)' % (roc_auc))\n",
    "    #plt.plot([eer], [1-eer], marker='o', markersize=5, color=\"navy\")\n",
    "    #plt.plot([0, 1], [1, 0], color='navy', lw=1, linestyle=':')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(y_test, y_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
